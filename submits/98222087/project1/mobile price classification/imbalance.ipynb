{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"dark\")\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn import linear_model, naive_bayes, neighbors, svm, tree, ensemble\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['price_range'].isin([1, 2, 3]), 'price_range'] = 4\n",
    "df['price_range'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Converts categorical variables to their appropriate type\n",
    "    Arguments:\n",
    "        df is a n-by-d pandas data frame\n",
    "    Returns:\n",
    "        the final dataframe with corrected categorical data types\n",
    "    '''\n",
    "\n",
    "    df_copy = df.copy(deep=True)\n",
    "    df_copy['blue'] = df.blue.astype('category')\n",
    "    df_copy['dual_sim'] = df.dual_sim.astype('category')\n",
    "    df_copy['four_g'] = df.four_g.astype('category')\n",
    "    df_copy['three_g'] = df.three_g.astype('category')\n",
    "    df_copy['touch_screen'] = df.touch_screen.astype('category')\n",
    "    df_copy['wifi'] = df.wifi.astype('category')\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'four_g',\n",
       "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'ram', 'talk_time',\n",
       "       'three_g', 'touch_screen', 'wifi', 'fc_sqrt', 'px_whole_sqrt',\n",
       "       'sc_whole_sqrt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_whole = df['px_width'] * df['px_height']\n",
    "sc_whole = df['sc_w'] * df['sc_h']\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Extract features form the original dataset\n",
    "    Arguments:\n",
    "        df is a n-by-d pandas data frame\n",
    "    Returns:\n",
    "        the final dataframe with extracted features\n",
    "    '''\n",
    "\n",
    "    df_copy = df.copy(deep=True)\n",
    "    df_copy['px_whole'] = px_whole\n",
    "    df_copy['sc_whole'] = sc_whole\n",
    "    df_copy.drop(['px_width', 'px_height', 'sc_h', 'sc_w'], axis=1, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_skewed_distributions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Apply square root to the skewed variables\n",
    "    Arguments:\n",
    "        df is a n-by-d pandas data frame\n",
    "    Returns:\n",
    "        the final dataframe with corrected skewed features\n",
    "    '''\n",
    "    \n",
    "    df_copy = df.copy(deep=True)\n",
    "    df_copy['fc_sqrt'] = np.sqrt(df['fc'])\n",
    "    df_copy['px_whole_sqrt'] = np.sqrt(df['px_whole'])\n",
    "    df_copy['sc_whole_sqrt'] = np.sqrt(df['sc_whole'])\n",
    "    df_copy.drop(['fc', 'px_whole', 'sc_whole'], inplace=True, axis=1)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  (1600, 20) (1600,)\n",
      "Test size:  (400, 20) (400,)\n"
     ]
    }
   ],
   "source": [
    "df_X = df.drop('price_range', axis=1)\n",
    "df_y = df['price_range']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y,test_size=0.2, stratify=df_y, random_state=42)\n",
    "print(\"Train size: \", X_train.shape, y_train.shape)\n",
    "print(\"Test size: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = add_features(X_train)\n",
    "X_test = add_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert_types(X_train)\n",
    "X_test = convert_types(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = handle_skewed_distributions(X_train)\n",
    "X_test = handle_skewed_distributions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train Accuracy Mean</th>\n",
       "      <th>Test Accuracy Mean</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'l1_ratios': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'refit': True, 'scoring': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0}</td>\n",
       "      <td>0.991771</td>\n",
       "      <td>0.979792</td>\n",
       "      <td>0.504643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}</td>\n",
       "      <td>0.988438</td>\n",
       "      <td>0.976875</td>\n",
       "      <td>0.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': None}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972917</td>\n",
       "      <td>0.149313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968125</td>\n",
       "      <td>0.321219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'bootstrap_features': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.047733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957083</td>\n",
       "      <td>0.257192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}</td>\n",
       "      <td>0.958958</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.007721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.955313</td>\n",
       "      <td>0.950833</td>\n",
       "      <td>0.005764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>0.00923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948958</td>\n",
       "      <td>0.202897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': True, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}</td>\n",
       "      <td>0.990208</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.185294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'random'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.853021</td>\n",
       "      <td>0.769583</td>\n",
       "      <td>0.006568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}</td>\n",
       "      <td>0.75375</td>\n",
       "      <td>0.747708</td>\n",
       "      <td>0.005966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Name  \\\n",
       "0         LogisticRegressionCV   \n",
       "6                    LinearSVC   \n",
       "9           AdaBoostClassifier   \n",
       "12  GradientBoostingClassifier   \n",
       "10           BaggingClassifier   \n",
       "13      RandomForestClassifier   \n",
       "1                SGDClassifier   \n",
       "3                   GaussianNB   \n",
       "7       DecisionTreeClassifier   \n",
       "11        ExtraTreesClassifier   \n",
       "5                          SVC   \n",
       "8          ExtraTreeClassifier   \n",
       "4         KNeighborsClassifier   \n",
       "2                  BernoulliNB   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                  Parameters  \\\n",
       "0                                                                                                                                             {'Cs': 10, 'class_weight': None, 'cv': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'l1_ratios': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'refit': True, 'scoring': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0}   \n",
       "6                                                                                                                                                                                                                         {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}   \n",
       "9                                                                                                                                                                                                                                                                                                                                           {'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': None}   \n",
       "12  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}   \n",
       "10                                                                                                                                                                                                                        {'base_estimator': None, 'bootstrap': True, 'bootstrap_features': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}   \n",
       "13                                                  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}   \n",
       "1                                        {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                   {'priors': None, 'var_smoothing': 1e-09}   \n",
       "7                                                                                                                                                                     {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}   \n",
       "11                                                 {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}   \n",
       "5                                                                                                                                                                     {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': True, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}   \n",
       "8                                                                                                                                                                 {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'random'}   \n",
       "4                                                                                                                                                                                                                                                                                                       {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                    {'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}   \n",
       "\n",
       "   Train Accuracy Mean Test Accuracy Mean      Time  \n",
       "0             0.991771           0.979792  0.504643  \n",
       "6             0.988438           0.976875  0.011628  \n",
       "9                  1.0           0.972917  0.149313  \n",
       "12                 1.0           0.968125  0.321219  \n",
       "10              0.9975              0.965  0.047733  \n",
       "13                 1.0           0.957083  0.257192  \n",
       "1             0.958958           0.953333  0.007721  \n",
       "3             0.955313           0.950833  0.005764  \n",
       "7                  1.0           0.950208   0.00923  \n",
       "11                 1.0           0.948958  0.202897  \n",
       "5             0.990208           0.940625  0.185294  \n",
       "8                  1.0               0.81   0.00571  \n",
       "4             0.853021           0.769583  0.006568  \n",
       "2              0.75375           0.747708  0.005966  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    svm.SVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "]\n",
    "\n",
    "model_result_columns = ['Model Name', 'Parameters', 'Train Accuracy Mean', 'Test Accuracy Mean', 'Time']\n",
    "model_result = pd.DataFrame(columns=model_result_columns)\n",
    "\n",
    "cv_split = ShuffleSplit(n_splits=10, test_size=.3, train_size=.6, random_state=0)\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    model_result.loc[index, 'Model Name'] = model.__class__.__name__\n",
    "    model_result.loc[index, 'Parameters'] = str(model.get_params())\n",
    "\n",
    "    cv_result = cross_validate(model, X_train, y_train, cv=cv_split, n_jobs=-1, return_train_score=True, scoring='f1_micro')\n",
    "    \n",
    "    model_result.loc[index, 'Time'] = cv_result['fit_time'].mean()\n",
    "    model_result.loc[index, 'Train Accuracy Mean'] = cv_result['train_score'].mean()\n",
    "    model_result.loc[index, 'Test Accuracy Mean'] = cv_result['test_score'].mean() \n",
    "\n",
    "model_result.sort_values(by=['Test Accuracy Mean'], ascending=False, inplace=True)\n",
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params_lgreg(X, y):\n",
    "    param_grid_lgreg = [\n",
    "        {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        },\n",
    "\n",
    "        {\n",
    "        'penalty': ['l2'],\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'solver': ['newton-cg', 'lbfgs', 'sag'],\n",
    "        },\n",
    "\n",
    "        {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': np.arange(0, 1, 0.01)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    tune_model_lgreg = RandomizedSearchCV(linear_model.LogisticRegression(), param_distributions=param_grid_lgreg,\n",
    "                                        scoring='f1_micro', cv=5, n_jobs=4, return_train_score=True, n_iter=50)\n",
    "    tune_model_lgreg.fit(X, y)\n",
    "\n",
    "    print(\"best parameters: \", tune_model_lgreg.best_params_)\n",
    "    print(\"Mean train score: \", tune_model_lgreg.cv_results_['mean_train_score'][tune_model_lgreg.best_index_] * 100)\n",
    "    print(\"Mean test Score: \", tune_model_lgreg.cv_results_['mean_test_score'][tune_model_lgreg.best_index_] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.5, 'C': 3792.690190732246}\n",
      "Mean train score:  98.90625\n",
      "Mean test Score:  98.4375\n"
     ]
    }
   ],
   "source": [
    "best_params_lgreg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ---\n",
      "[[ 392    8]\n",
      " [   9 1191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       400\n",
      "           4       0.99      0.99      0.99      1200\n",
      "\n",
      "    accuracy                           0.99      1600\n",
      "   macro avg       0.99      0.99      0.99      1600\n",
      "weighted avg       0.99      0.99      0.99      1600\n",
      "\n",
      "--- TEST ---\n",
      "[[ 99   1]\n",
      " [  6 294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       100\n",
      "           4       1.00      0.98      0.99       300\n",
      "\n",
      "    accuracy                           0.98       400\n",
      "   macro avg       0.97      0.98      0.98       400\n",
      "weighted avg       0.98      0.98      0.98       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegressionCV(Cs=np.linspace(500, 650, 20), solver='saga', penalty='elasticnet', l1_ratios=np.arange(0.3, 0.7, 0.05))\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_train)\n",
    "\n",
    "print(\"--- Train ---\")\n",
    "print(confusion_matrix(y_train, y_hat))\n",
    "print(classification_report(y_train, y_hat))\n",
    "\n",
    "print(\"--- TEST ---\")\n",
    "y_hat_test = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes before fit: Counter({4: 1200, 0: 400})\n",
      "Number of classes after fit: Counter({0: 400, 4: 400})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "ns = NearMiss()\n",
    "X_train_ns, y_train_ns = ns.fit_resample(X_train, y_train)\n",
    "print('Number of classes before fit: {}'.format(Counter(y_train)))\n",
    "print('Number of classes after fit: {}'.format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.26, 'C': 206.913808111479}\n",
      "Mean train score:  98.75\n",
      "Mean test Score:  97.24999999999999\n"
     ]
    }
   ],
   "source": [
    "best_params_lgreg(X_train_ns, y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ---\n",
      "[[397   3]\n",
      " [  7 393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       400\n",
      "           4       0.99      0.98      0.99       400\n",
      "\n",
      "    accuracy                           0.99       800\n",
      "   macro avg       0.99      0.99      0.99       800\n",
      "weighted avg       0.99      0.99      0.99       800\n",
      "\n",
      "--- TEST ---\n",
      "[[ 98   2]\n",
      " [  8 292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       100\n",
      "           4       0.99      0.97      0.98       300\n",
      "\n",
      "    accuracy                           0.97       400\n",
      "   macro avg       0.96      0.98      0.97       400\n",
      "weighted avg       0.98      0.97      0.98       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_under = linear_model.LogisticRegressionCV(Cs=np.linspace(100, 300, 20), solver='saga', penalty='elasticnet', l1_ratios=np.arange(0.2, 0.4, 0.05))\n",
    "model_under.fit(X_train_ns, y_train_ns)\n",
    "y_hat_ns = model_under.predict(X_train_ns)\n",
    "\n",
    "print(\"--- Train ---\")\n",
    "print(confusion_matrix(y_train_ns, y_hat_ns))\n",
    "print(classification_report(y_train_ns, y_hat_ns))\n",
    "\n",
    "print(\"--- TEST ---\")\n",
    "y_hat_test_ns = model_under.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_hat_test_ns))\n",
    "print(classification_report(y_test, y_hat_test_ns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes before fit: Counter({4: 1200, 0: 400})\n",
      "Number of classes after fit: Counter({4: 1200, 0: 1200})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "os = RandomOverSampler()\n",
    "X_train_os, y_train_os = os.fit_resample(X_train, y_train)\n",
    "print('Number of classes before fit: {}'.format(Counter(y_train)))\n",
    "print('Number of classes after fit: {}'.format(Counter(y_train_os)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'solver': 'sag', 'penalty': 'l2', 'C': 3792.690190732246}\n",
      "Mean train score:  99.125\n",
      "Mean test Score:  98.83333333333333\n"
     ]
    }
   ],
   "source": [
    "best_params_lgreg(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ---\n",
      "[[1200    0]\n",
      " [  18 1182]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1200\n",
      "           4       1.00      0.98      0.99      1200\n",
      "\n",
      "    accuracy                           0.99      2400\n",
      "   macro avg       0.99      0.99      0.99      2400\n",
      "weighted avg       0.99      0.99      0.99      2400\n",
      "\n",
      "--- TEST ---\n",
      "[[100   0]\n",
      " [  9 291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       100\n",
      "           4       1.00      0.97      0.98       300\n",
      "\n",
      "    accuracy                           0.98       400\n",
      "   macro avg       0.96      0.98      0.97       400\n",
      "weighted avg       0.98      0.98      0.98       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_over = linear_model.LogisticRegressionCV(Cs=np.linspace(3600, 3900, 20), solver='sag', penalty='l2')\n",
    "model_over.fit(X_train_os, y_train_os)\n",
    "y_hat_os = model_over.predict(X_train_os)\n",
    "\n",
    "print(\"--- Train ---\")\n",
    "print(confusion_matrix(y_train_os, y_hat_os))\n",
    "print(classification_report(y_train_os, y_hat_os))\n",
    "\n",
    "print(\"--- TEST ---\")\n",
    "y_hat_test_os = model_over.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_hat_test_os))\n",
    "print(classification_report(y_test, y_hat_test_os))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes before fit: Counter({4: 1200, 0: 400})\n",
      "Number of classes after fit: Counter({4: 1200, 0: 1200})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "sm = SMOTENC(categorical_features=[1, 3, 4, 12, 13, 14])\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "print('Number of classes before fit: {}'.format(Counter(y_train)))\n",
    "print('Number of classes after fit: {}'.format(Counter(y_train_sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.92, 'C': 1.623776739188721}\n",
      "Mean train score:  98.89583333333334\n",
      "Mean test Score:  98.70833333333333\n"
     ]
    }
   ],
   "source": [
    "best_params_lgreg(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ---\n",
      "[[1199    1]\n",
      " [  20 1180]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1200\n",
      "           4       1.00      0.98      0.99      1200\n",
      "\n",
      "    accuracy                           0.99      2400\n",
      "   macro avg       0.99      0.99      0.99      2400\n",
      "weighted avg       0.99      0.99      0.99      2400\n",
      "\n",
      "--- TEST ---\n",
      "[[100   0]\n",
      " [  8 292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       100\n",
      "           4       1.00      0.97      0.99       300\n",
      "\n",
      "    accuracy                           0.98       400\n",
      "   macro avg       0.96      0.99      0.97       400\n",
      "weighted avg       0.98      0.98      0.98       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_sm = linear_model.LogisticRegressionCV(Cs=20, solver='saga', penalty='elasticnet', l1_ratios=np.arange(0.8, 1, 0.05))\n",
    "model_sm.fit(X_train_sm, y_train_sm)\n",
    "y_hat_sm = model_sm.predict(X_train_sm)\n",
    "\n",
    "print(\"--- Train ---\")\n",
    "print(confusion_matrix(y_train_sm, y_hat_sm))\n",
    "print(classification_report(y_train_sm, y_hat_sm))\n",
    "\n",
    "print(\"--- TEST ---\")\n",
    "y_hat_test_sm = model_sm.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_hat_test_sm))\n",
    "print(classification_report(y_test, y_hat_test_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### handle imbalanced data using class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ---\n",
      "[[ 400    0]\n",
      " [  18 1182]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       400\n",
      "           4       1.00      0.98      0.99      1200\n",
      "\n",
      "    accuracy                           0.99      1600\n",
      "   macro avg       0.98      0.99      0.99      1600\n",
      "weighted avg       0.99      0.99      0.99      1600\n",
      "\n",
      "--- TEST ---\n",
      "[[100   0]\n",
      " [  9 291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       100\n",
      "           4       1.00      0.97      0.98       300\n",
      "\n",
      "    accuracy                           0.98       400\n",
      "   macro avg       0.96      0.98      0.97       400\n",
      "weighted avg       0.98      0.98      0.98       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegressionCV(Cs=np.linspace(500, 650, 20), solver='saga',\n",
    "                                          penalty='elasticnet', l1_ratios=np.arange(0.3, 0.7, 0.05),\n",
    "                                          class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_train)\n",
    "\n",
    "print(\"--- Train ---\")\n",
    "print(confusion_matrix(y_train, y_hat))\n",
    "print(classification_report(y_train, y_hat))\n",
    "\n",
    "print(\"--- TEST ---\")\n",
    "y_hat_test = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_hat_test))\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b03d4cd05d71d535371b426da57de743181e37d8974a9636efe6e78873daaed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
